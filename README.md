# Image Colourization
Converting gray scale images to colour using deep neural networks.

## Methods

We trained and tested the model on a subset of two larger datasets. To examine the performance of the model on colourizing 

## Datasets:

To explore a variety of domains for colourization techniques, two different datasets were used and analyzed. The first dataset used to train the neural networks with is the [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) dataset. This dataset is composed of a diversity of face attributes with many images of celebrities. The images in this dataset have many properties that can help neural network models find patterns such as faces that are wearing hats or glasses, faces that have facial hair, and even different expressions on faces. This dataset will examine the effectiveness of colourization on images with people. 

Another dataset used to train the models is sample sample of the ImageNet dataset, called [Imagenette](https://www.tensorflow.org/datasets/catalog/imagenette). The original ImageNet dataset is based on the words in the WordNet hierarchy and contains over 14 million images divided accross 1000 classes. The Imagenette dataset is a lot smaller and contains only 10 classes of objects. By having different types of objects, this will test if the neural network can differentiate the colouring based on context and patterns. Overall, this dataset evaluates the colourization of more common objects, places and landscapes. 


## Results



### Contributors:
Ilan Gofman: [@ilangofman](https://github.com/ilangofman)

Daniel Truong: [@daniel-truong](https://github.com/Daniel-Truong)

Vatsan Prabhu: [@vatsanp](https://github.com/vatsanp)
